{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load necessary libraries\n",
    "# librosa, numpy, pandas, sklearn, etc.\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "import sklearn\n",
    "import audioread\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Define a function to extract music features\n",
    "# You may consider MFCC, Chroma STFT, Spectral Contrast, Zero Crossing Rate, Tempo, etc\n",
    "# Be sure to have the feature dimension as large as possible, to get higher performance\n",
    "# librosa.feature and librosa.beat may contain many useful functions\n",
    "\n",
    "def extract_features(audio_file):\n",
    "    with audioread.audio_open(audio_file) as f:\n",
    "        sr = f.samplerate\n",
    "\n",
    "    y, sr = librosa.load(audio_file, sr=sr, duration=44)\n",
    "    \n",
    "    tempo, beat_frames = librosa.beat.beat_track(y=y, sr=sr)\n",
    "    \n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    chroma_stft_mean = np.mean(chroma_stft)\n",
    "    chroma_stft_var = np.var(chroma_stft)\n",
    "    \n",
    "    spectral_centroid = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spectral_centroid_mean = np.mean(spectral_centroid)\n",
    "    spectral_centroid_var = np.var(spectral_centroid)\n",
    "    \n",
    "    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    spectral_bandwidth_mean = np.mean(spectral_bandwidth)\n",
    "    spectral_bandwidth_var = np.var(spectral_bandwidth)\n",
    "    \n",
    "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
    "    spectral_contrast_mean = np.mean(spectral_contrast)\n",
    "    spectral_contrast_var = np.var(spectral_contrast)\n",
    "    \n",
    "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y)\n",
    "    zero_crossing_rate_mean = np.mean(zero_crossing_rate)\n",
    "    zero_crossing_rate_var = np.var(zero_crossing_rate)\n",
    "    \n",
    "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=20)\n",
    "    mfccs_mean = np.mean(mfccs, axis=1)\n",
    "    mfccs_var = np.var(mfccs, axis=1)\n",
    "    \n",
    "    features = {\n",
    "        'tempo': tempo.reshape(1,)[0],\n",
    "        'beat_frames': beat_frames.mean(axis=0),\n",
    "        'chroma_stft_mean': chroma_stft_mean,\n",
    "        'chroma_stft_var': chroma_stft_var,\n",
    "        'zero_crossing_rate_mean': zero_crossing_rate_mean,\n",
    "        'zero_crossing_rate_var': zero_crossing_rate_var,\n",
    "        'spectral_centroid_mean': spectral_centroid_mean,\n",
    "        'spectral_centroid_var': spectral_centroid_var,\n",
    "        'spectral_bandwidth_mean': spectral_bandwidth_mean,\n",
    "        'spectral_bandwidth_var': spectral_bandwidth_var,\n",
    "        'spectral_contrast_mean': spectral_contrast_mean,\n",
    "        'spectral_contrast_var': spectral_contrast_var,\n",
    "        'mfcc1_mean': mfccs_mean[0],\n",
    "        'mfcc1_var': mfccs_var[0],\n",
    "        'mfcc2_mean': mfccs_mean[1],\n",
    "        'mfcc2_var': mfccs_var[1],\n",
    "        'mfcc3_mean': mfccs_mean[2],\n",
    "        'mfcc3_var': mfccs_var[2],\n",
    "        'mfcc4_mean': mfccs_mean[3],\n",
    "        'mfcc4_var': mfccs_var[3],\n",
    "        'mfcc5_mean': mfccs_mean[4],\n",
    "        'mfcc5_var': mfccs_var[4],\n",
    "        'mfcc6_mean': mfccs_mean[5],\n",
    "        'mfcc6_var': mfccs_var[5],\n",
    "        'mfcc7_mean': mfccs_mean[6],\n",
    "        'mfcc7_var': mfccs_var[6],\n",
    "        'mfcc8_mean': mfccs_mean[7],\n",
    "        'mfcc8_var': mfccs_var[7],\n",
    "        'mfcc9_mean': mfccs_mean[8],\n",
    "        'mfcc9_var': mfccs_var[8],\n",
    "        'mfcc10_mean': mfccs_mean[9],\n",
    "        'mfcc10_var': mfccs_var[9],\n",
    "        'mfcc11_mean': mfccs_mean[10],\n",
    "        'mfcc11_var': mfccs_var[10],\n",
    "        'mfcc12_mean': mfccs_mean[11],\n",
    "        'mfcc12_var': mfccs_var[11],\n",
    "        'mfcc13_mean': mfccs_mean[12],\n",
    "        'mfcc13_var': mfccs_var[12],\n",
    "        'mfcc14_mean': mfccs_mean[13],\n",
    "        'mfcc14_var': mfccs_mean[13],\n",
    "        'mfcc15_mean': mfccs_mean[14],\n",
    "        'mfcc15_var': mfccs_mean[14],\n",
    "        'mfcc16_mean': mfccs_mean[15],\n",
    "        'mfcc16_var': mfccs_mean[15],\n",
    "        'mfcc17_mean': mfccs_mean[16],\n",
    "        'mfcc17_var': mfccs_mean[16],\n",
    "        'mfcc18_mean': mfccs_mean[17],\n",
    "        'mfcc18_var': mfccs_mean[17],\n",
    "        'mfcc19_mean': mfccs_mean[18],\n",
    "        'mfcc19_var': mfccs_mean[18],\n",
    "        'mfcc20_mean': mfccs_mean[19],\n",
    "        'mfcc20_var': mfccs_mean[19],\n",
    "    }\n",
    "\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from librosa.beat import beat_track\n",
    "# Step 3: Iterate through each genre folder and extract features for each song\n",
    "# Remember to mount Google Drive before accessing the dataset\n",
    "# Useful python funtions: os.listdir, pandas.DataFrame\n",
    "\n",
    "feature_names = [\n",
    "    'tempo',\n",
    "    'beat_frames',\n",
    "    'chroma_stft_mean',\n",
    "    'chroma_stft_var',\n",
    "    'zero_crossing_rate_mean',\n",
    "    'zero_crossing_rate_var',\n",
    "    'spectral_centroid_mean',\n",
    "    'spectral_centroid_var',\n",
    "    'spectral_bandwidth_mean',\n",
    "    'spectral_bandwidth_var',\n",
    "    'spectral_contrast_mean',\n",
    "    'spectral_contrast_var',\n",
    "    'mfcc1_mean',\n",
    "    'mfcc1_var',\n",
    "    'mfcc2_mean',\n",
    "    'mfcc2_var',\n",
    "    'mfcc3_mean',\n",
    "    'mfcc3_var',\n",
    "    'mfcc4_mean',\n",
    "    'mfcc4_var',\n",
    "    'mfcc5_mean',\n",
    "    'mfcc5_var',\n",
    "    'mfcc6_mean',\n",
    "    'mfcc6_var',\n",
    "    'mfcc7_mean',\n",
    "    'mfcc7_var',\n",
    "    'mfcc8_mean',\n",
    "    'mfcc8_var',\n",
    "    'mfcc9_mean',\n",
    "    'mfcc9_var',\n",
    "    'mfcc10_mean',\n",
    "    'mfcc10_var',\n",
    "    'mfcc11_mean',\n",
    "    'mfcc11_var',\n",
    "    'mfcc12_mean',\n",
    "    'mfcc12_var',\n",
    "    'mfcc13_mean',\n",
    "    'mfcc13_var',\n",
    "    'mfcc14_mean',\n",
    "    'mfcc14_var',\n",
    "    'mfcc15_mean',\n",
    "    'mfcc15_var',\n",
    "    'mfcc16_mean',\n",
    "    'mfcc16_var',\n",
    "    'mfcc17_mean',\n",
    "    'mfcc17_var',\n",
    "    'mfcc18_mean',\n",
    "    'mfcc18_var',\n",
    "    'mfcc19_mean',\n",
    "    'mfcc19_var',\n",
    "    'mfcc20_mean',\n",
    "    'mfcc20_var'\n",
    "]\n",
    "\n",
    "features_df = pd.DataFrame(columns=['arousal', 'valence', 'file_name'] + feature_names)\n",
    "\n",
    "annotation = pd.read_csv('annotations/static_annotations.csv')\n",
    "min_duration = []\n",
    "\n",
    "root_folder = 'clips_45seconds'\n",
    "for file_name in os.listdir(root_folder):\n",
    "    if not file_name.endswith(\".mp3\"):\n",
    "        continue\n",
    "    file_path = os.path.join(root_folder, file_name)\n",
    "    index_value = int(os.path.splitext(file_name)[0])\n",
    "    annotation_row = annotation.loc[annotation['song_id'] == index_value]\n",
    "    if not annotation_row.empty:\n",
    "        arousal = annotation_row.iloc[0]['mean_arousal']\n",
    "        valence = annotation_row.iloc[0]['mean_valence']\n",
    "        print(file_path)\n",
    "        # print(f'arousal: {arousal}, valence: {valence}')\n",
    "        # with audioread.audio_open(file_path) as f:\n",
    "        #     sr = f.samplerate\n",
    "        # y,sr = librosa.load(file_path, sr=sr)\n",
    "        # duration = librosa.get_duration(y=y)\n",
    "        # print(duration)\n",
    "        # if duration < 45:\n",
    "        #     print(file_name)\n",
    "        #     min_duration.append(file_name)\n",
    "\n",
    "        features = extract_features(file_path)\n",
    "        print(features)\n",
    "  \n",
    "        row = {'arousal': arousal, 'valence': valence, 'file_name': file_name}\n",
    "        for i, feature_name in enumerate(feature_names):\n",
    "            row[feature_name] = features[feature_name]\n",
    "            \n",
    "        features_df = features_df.append(row, ignore_index=True)\n",
    "\n",
    "# print(min_duration)\n",
    "features_df.to_csv('my_mood_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595, 52)\n",
      "(149, 52)\n",
      "LR\n",
      "RMSE: 0.1288626565416605\n",
      "R-squared score: 0.5996583292717952\n",
      "NB\n",
      "RMSE: 0.12986128675931027\n",
      "R-squared score: 0.5934293345630169\n",
      "SVM\n",
      "RMSE: 0.13112723938949541\n",
      "R-squared score: 0.5854637893490551\n",
      "RF\n",
      "RMSE: 0.13284915112407905\n",
      "R-squared score: 0.5745052515803315\n"
     ]
    }
   ],
   "source": [
    "features_df = pd.read_csv('my_mood_features.csv')\n",
    "features_df\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-0.5, 0.5))\n",
    "features_df[['arousal']] = scaler.fit_transform(features_df[['arousal']])\n",
    "\n",
    "train_df, test_df = train_test_split(features_df, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "y_train = train_df['arousal']\n",
    "train_df.drop(['arousal','file_name', 'valence'], axis=1, inplace=True)\n",
    "X_train_df = train_df\n",
    "\n",
    "y_test = test_df['arousal']\n",
    "y_test_filename = test_df['file_name']\n",
    "test_df.drop(['arousal','file_name', 'valence'], axis=1, inplace=True)\n",
    "X_test_df = test_df\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_df)\n",
    "X_test = scaler.transform(X_test_df)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = lr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('LR')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')\n",
    "\n",
    "br = BayesianRidge()\n",
    "br.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = br.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('NB')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')\n",
    "\n",
    "# Create an instance of the SVM regressor\n",
    "svr = SVR(kernel='linear', C=1.0, epsilon=0.1)\n",
    "\n",
    "# Train the model on the training data\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the test data\n",
    "test_predictions = svr.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('SVM')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = rf.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('RF')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arousal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.147059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.326794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.220588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.088235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>0.235294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>-0.044118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>0.147059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>0.205882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>-0.132353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      arousal\n",
       "0   -0.147059\n",
       "1    0.326794\n",
       "2   -0.235294\n",
       "3    0.220588\n",
       "4    0.088235\n",
       "..        ...\n",
       "739  0.235294\n",
       "740 -0.044118\n",
       "741  0.147059\n",
       "742  0.205882\n",
       "743 -0.132353\n",
       "\n",
       "[744 rows x 1 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df[['arousal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595, 52)\n",
      "(149, 52)\n",
      "LR\n",
      "RMSE: 0.12886265654130158\n",
      "R-squared score: 0.5996583292740252\n",
      "NB\n",
      "RMSE: 0.1328673278473822\n",
      "R-squared score: 0.5743888092945941\n",
      "RF\n",
      "RMSE: 0.13288370940295158\n",
      "R-squared score: 0.5742838534217988\n"
     ]
    }
   ],
   "source": [
    "features_df = pd.read_csv('my_mood_features.csv')\n",
    "features_df\n",
    "\n",
    "# Scale the 'arousal' column\n",
    "scaler = MinMaxScaler(feature_range=(-0.5, 0.5))\n",
    "features_df[['arousal']] = scaler.fit_transform(features_df[['arousal']])\n",
    "\n",
    "train_df, test_df = train_test_split(features_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "y_train = train_df['arousal']\n",
    "train_df.drop(['arousal','file_name', 'valence'], axis=1, inplace=True)\n",
    "X_train_df = train_df\n",
    "\n",
    "y_test = test_df['arousal']\n",
    "y_test_filename = test_df['file_name']\n",
    "test_df.drop(['arousal','file_name', 'valence'], axis=1, inplace=True)\n",
    "X_test_df = test_df\n",
    "\n",
    "# X_train = scaler.fit_transform(X_train_df)\n",
    "# X_test = scaler.transform(X_test_df)\n",
    "\n",
    "X_train = np.array(X_train_df.values.tolist())\n",
    "\n",
    "X_test = np.array(X_test_df.values.tolist())\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = lr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('LR')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')\n",
    "\n",
    "br = BayesianRidge()\n",
    "br.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = br.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('NB')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')\n",
    "\n",
    "# # Create an instance of the SVM regressor\n",
    "# svr = SVR(kernel='linear', C=1.0, epsilon=0.1)\n",
    "\n",
    "# # Train the model on the training data\n",
    "# svr.fit(X_train, y_train)\n",
    "\n",
    "# # Test the model on the test data\n",
    "# test_predictions = svr.predict(X_test)\n",
    "\n",
    "# # Evaluate the performance of the model\n",
    "# mse = mean_squared_error(y_test, test_predictions)\n",
    "# r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "# print('SVM')\n",
    "# rmse = math.sqrt(mse)\n",
    "# print(f'RMSE: {rmse}')\n",
    "# print(f'R-squared score: {r2}')\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = rf.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('RF')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LR_arousal.sav']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to disk\n",
    "filename = 'LR_arousal.sav'\n",
    "joblib.dump(lr, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595, 52)\n",
      "(149, 52)\n",
      "LR\n",
      "RMSE: 0.17868104273710395\n",
      "R-squared score: 0.14850482074723537\n",
      "NB\n",
      "RMSE: 0.17496229541987862\n",
      "R-squared score: 0.18357898958257268\n",
      "SVM\n",
      "RMSE: 0.1815039308072443\n",
      "R-squared score: 0.12138764310991801\n",
      "RF\n",
      "RMSE: 0.16905860752281088\n",
      "R-squared score: 0.23774582437466518\n"
     ]
    }
   ],
   "source": [
    "features_df = pd.read_csv('my_mood_features.csv')\n",
    "features_df\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(-0.5, 0.5))\n",
    "features_df[['valence']] = scaler.fit_transform(features_df[['valence']])\n",
    "\n",
    "train_df, test_df = train_test_split(features_df, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "y_train = train_df['valence']\n",
    "train_df.drop(['arousal','file_name', 'valence'], axis=1, inplace=True)\n",
    "X_train_df = train_df\n",
    "\n",
    "y_test = test_df['valence']\n",
    "y_test_filename = test_df['file_name']\n",
    "test_df.drop(['arousal','file_name', 'valence'], axis=1, inplace=True)\n",
    "X_test_df = test_df\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_df)\n",
    "X_test = scaler.transform(X_test_df)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = lr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('LR')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')\n",
    "\n",
    "br = BayesianRidge()\n",
    "br.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = br.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('NB')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')\n",
    "\n",
    "# Create an instance of the SVM regressor\n",
    "svr = SVR(kernel='linear', C=1.0, epsilon=0.1)\n",
    "\n",
    "# Train the model on the training data\n",
    "svr.fit(X_train, y_train)\n",
    "\n",
    "# Test the model on the test data\n",
    "test_predictions = svr.predict(X_test)\n",
    "\n",
    "# Evaluate the performance of the model\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('SVM')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = rf.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('RF')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(595, 52)\n",
      "(149, 52)\n",
      "LR\n",
      "RMSE: 0.17868104275533178\n",
      "R-squared score: 0.1485048205735079\n",
      "NB\n",
      "RMSE: 0.168696284434891\n",
      "R-squared score: 0.24100961953432176\n",
      "RF\n",
      "RMSE: 0.16905860752281088\n",
      "R-squared score: 0.23774582437466518\n"
     ]
    }
   ],
   "source": [
    "features_df = pd.read_csv('my_mood_features.csv')\n",
    "features_df\n",
    "\n",
    "# Scale the 'arousal' column\n",
    "scaler = MinMaxScaler(feature_range=(-0.5, 0.5))\n",
    "features_df[['valence']] = scaler.fit_transform(features_df[['valence']])\n",
    "\n",
    "train_df, test_df = train_test_split(features_df, test_size=0.2, random_state=42)\n",
    "\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "y_train = train_df['valence']\n",
    "train_df.drop(['arousal','file_name', 'valence'], axis=1, inplace=True)\n",
    "X_train_df = train_df\n",
    "\n",
    "y_test = test_df['valence']\n",
    "y_test_filename = test_df['file_name']\n",
    "test_df.drop(['arousal','file_name', 'valence'], axis=1, inplace=True)\n",
    "X_test_df = test_df\n",
    "\n",
    "# X_train = scaler.fit_transform(X_train_df)\n",
    "# X_test = scaler.transform(X_test_df)\n",
    "\n",
    "X_train = np.array(X_train_df.values.tolist())\n",
    "\n",
    "X_test = np.array(X_test_df.values.tolist())\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = lr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('LR')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')\n",
    "\n",
    "br = BayesianRidge()\n",
    "br.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = br.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('NB')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')\n",
    "\n",
    "# # Create an instance of the SVM regressor\n",
    "# svr = SVR(kernel='linear', C=1.0, epsilon=0.1)\n",
    "\n",
    "# # Train the model on the training data\n",
    "# svr.fit(X_train, y_train)\n",
    "\n",
    "# # Test the model on the test data\n",
    "# test_predictions = svr.predict(X_test)\n",
    "\n",
    "# # Evaluate the performance of the model\n",
    "# mse = mean_squared_error(y_test, test_predictions)\n",
    "# r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "# print('SVM')\n",
    "# rmse = math.sqrt(mse)\n",
    "# print(f'RMSE: {rmse}')\n",
    "# print(f'R-squared score: {r2}')\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "test_predictions = rf.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, test_predictions)\n",
    "r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "print('RF')\n",
    "rmse = math.sqrt(mse)\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R-squared score: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RF_valence.sav']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model to disk\n",
    "filename = 'RF_valence.sav'\n",
    "joblib.dump(rf, filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
